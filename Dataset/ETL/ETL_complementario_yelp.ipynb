{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías\n",
    "import pandas as pd  # type: ignore # Para manipulación de datos\n",
    "import ast  # Para evaluar strings como expresiones de Python\n",
    "import re  # Para expresiones regulares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos\n",
    "# Cargar el archivo de business\n",
    "business = pd.read_csv(r'business.csv')\n",
    "\n",
    "# Cargar el archivo de categorías normalizadas\n",
    "categorias = pd.read_csv(r'categorias_normalizadas.csv')\n",
    "\n",
    "# Cargar el archivo de categorías normalizadas\n",
    "ciudades = pd.read_csv(r'data_normalizada\\ciudades_normal.csv')\n",
    "\n",
    "# Cargar el archivo de categorías normalizadas\n",
    "reviews = pd.read_csv(r'reviews_yelp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para convertir strings a listas\n",
    "def convertir_a_lista(valor):\n",
    "    \"\"\"\n",
    "    Convierte un string que representa una lista en una lista real de Python.\n",
    "    \n",
    "    Parámetros:\n",
    "    - valor: El valor a convertir, puede ser un string o una lista.\n",
    "    \n",
    "    Retorna:\n",
    "    - Una lista si el valor era un string que representaba una lista.\n",
    "    - Una lista con un solo elemento si el valor era un string que no representaba una lista.\n",
    "    - Una lista vacía si el valor no era un string o si había un error en la conversión.\n",
    "    \"\"\"\n",
    "    if isinstance(valor, str):\n",
    "        try:\n",
    "            lista = ast.literal_eval(valor)  # Convierte el string en una lista real\n",
    "            if isinstance(lista, list):\n",
    "                return lista\n",
    "            return [lista]  # Si era un solo valor, convertirlo en lista\n",
    "        except:\n",
    "            return []  # Si hay un error, devolver una lista vacía\n",
    "    return valor  # Si ya es una lista, dejarlo igual\n",
    "\n",
    "# Aplicar la función a la columna 'categories' del DataFrame business\n",
    "business['categories'] = business['categories'].dropna().apply(convertir_a_lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para normalizar nombres de categorías\n",
    "def normalizar_categoria(cat):\n",
    "    \"\"\"\n",
    "    Normaliza el nombre de una categoría eliminando espacios extra, caracteres especiales, etc.\n",
    "    \n",
    "    Parámetros:\n",
    "    - cat: El nombre de la categoría a normalizar.\n",
    "    \n",
    "    Retorna:\n",
    "    - El nombre de la categoría normalizado o None si la categoría queda vacía.\n",
    "    \"\"\"\n",
    "    cat = cat.lower().strip()  # Minúsculas y eliminar espacios extra\n",
    "    cat = re.sub(r'\\s*,\\s*', ',', cat)  # Asegurar que las comas no tengan espacios extra\n",
    "    cat = re.sub(r'\\s*restaurant[s]?\\b', '', cat)  # Eliminar 'restaurant' y variantes\n",
    "    cat = re.sub(r'[^a-z\\s,]', '', cat)  # Remover caracteres especiales excepto espacios y comas\n",
    "    cat = re.sub(r'\\s+', ' ', cat)  # Reemplazar múltiples espacios por uno solo\n",
    "    cat = cat.strip()\n",
    "    \n",
    "    return cat if cat else None  # Devolver None si la categoría queda vacía\n",
    "\n",
    "# Aplicar normalización a cada elemento dentro de las listas de categorías\n",
    "business['categories'] = business['categories'].apply(\n",
    "    lambda lista: list(set(filter(None, [normalizar_categoria(cat) for cat in lista]))) or [\"restaurant\"]\n",
    ")\n",
    "\n",
    "# %% Crear un diccionario de mapeo {Categoria: category_id}\n",
    "category_map = dict(zip(categorias['category'], categorias['category_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para mapear categorías a IDs\n",
    "def map_categories_to_ids(category_list):\n",
    "    \"\"\"\n",
    "    Mapea una lista de categorías a sus respectivos IDs.\n",
    "    \n",
    "    Parámetros:\n",
    "    - category_list: Lista de categorías a mapear.\n",
    "    \n",
    "    Retorna:\n",
    "    - Lista de IDs correspondientes a las categorías.\n",
    "    \"\"\"\n",
    "    return [category_map[c.strip().lower()] for c in category_list if c.strip().lower() in category_map]\n",
    "\n",
    "# Aplicar la transformación\n",
    "business['category_id'] = business['categories'].apply(map_categories_to_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificación de ciudades en business que no están en el DataFrame \"ciudades\"\n",
    "# Asegurar que los nombres de ciudad en ambos DataFrames estén en el mismo formato\n",
    "business['city_normalized'] = business['city'].str.strip().str.title()\n",
    "ciudades['city_normalized'] = ciudades['city'].str.strip().str.title()\n",
    "\n",
    "# Normalización de nombres de ciudades en `business` y `ciudades`\n",
    "def normalizar_ciudad(nombre):\n",
    "    \"\"\"\n",
    "    Normaliza el nombre de una ciudad eliminando abreviaciones, espacios extra, etc.\n",
    "    \n",
    "    Parámetros:\n",
    "    - nombre: El nombre de la ciudad a normalizar.\n",
    "    \n",
    "    Retorna:\n",
    "    - El nombre de la ciudad normalizado.\n",
    "    \"\"\"\n",
    "    nombre = nombre.strip().title()  # Eliminar espacios y convertir en formato título\n",
    "    nombre = nombre.replace(\"St.\", \"Saint\")  # Reemplazar abreviaciones comunes\n",
    "    nombre = nombre.replace(\"Ft.\", \"Fort\")\n",
    "    nombre = nombre.replace(\"Mt.\", \"Mount\")\n",
    "    nombre = nombre.replace(\" N \", \" North \").replace(\" S \", \" South \")\n",
    "    nombre = nombre.replace(\" E \", \" East \").replace(\" W \", \" West \")\n",
    "    nombre = nombre.replace(\"-\", \" \")  # Convertir guiones en espacios\n",
    "    nombre = nombre.replace(\"'\", \"\")  # Eliminar apóstrofes\n",
    "    return nombre.strip()\n",
    "\n",
    "# Aplicar normalización a ambas listas de ciudades\n",
    "business['city_normalized'] = business['city'].apply(normalizar_ciudad)\n",
    "ciudades['city_normalized'] = ciudades['city'].apply(normalizar_ciudad)\n",
    "\n",
    "# Mapeo de nombres de ciudades\n",
    "city_mapping_unificado = {\n",
    "    \"Islamorada, Village Of Islands\": [\"Islamorada\"],\n",
    "    \"St. Cloud\": [\"St Cloud\"],\n",
    "    \"Port St. Joe\": [\"Port St Joe\"],\n",
    "    \"Wesley Chapel\": [\"Wesley Chapel South\"],\n",
    "    \"Northdale\": [\"Greater Northdale\"],\n",
    "    \"Carrollwood\": [\"Greater Carrollwood\"],\n",
    "    \"Tampa\": [\"Ybor City\"],\n",
    "    \"St. Pete Beach\": [\"St Pete Beach\", \"Pass-A-Grille Beach\", \"St. Pete Beach\"],\n",
    "    \"Clearwater\": [\"Clearwater Beach\"],\n",
    "    \"Rotonda\": [\"Rotonda West\"],\n",
    "    \"Islamorada, Village Of Islands\": [\"Islamorada\"],\n",
    "    \"Lake Worth Beach\": [\"Lake Worth\"],\n",
    "    \"Plantation City\": [\"Plantation\"],\n",
    "    \"Miami Gardens\": [\"Carol City\"],\n",
    "    \"Hollywood\": [\"Hollywood Beach\"],\n",
    "    \"Miami\": [\"Coconut Grove\"],\n",
    "    \"St. James City\": [\"St James City\"],\n",
    "    \"Port St. John\": [\"Port St John\"],\n",
    "    \"Glen St. Mary\": [\"Glen St Mary\"],\n",
    "    \"Laurel\": [\"Laurel Hill\"],\n",
    "    \"Pensacola\": [\"Pensacola Beach\", \"Cantonment\"],\n",
    "    \"Pace\": [\"Milton\"],\n",
    "    \"Crestview\": [\"Holt\", \"Baker\"],\n",
    "    \"Fort Walton Beach\": [\"Shalimar\"],\n",
    "    \"Destin\": [\"Santa Rosa Beach\", \"Sandestin\"],\n",
    "    \"Marianna\": [\"Alford\"],\n",
    "    \"Panama City\": [\"Wewahitchka\", \"Ebro\", \"Southport\"],\n",
    "    \"Panama City Beach\": [\"Inlet Beach\", \"Alys Beach\", \"Seacrest\", \"Rosemary Beach\"],\n",
    "    \"DeFuniak Springs\": [\"Redbay\", \"Ponce De Leon\"],\n",
    "    \"Brandon\": [\"Lithia\"],\n",
    "    \"St. Pete Beach\": [\"Pass-A-Grille Beach\", \"St Pete Beach\"],\n",
    "    \"Bradenton\": [\"Parrish\"],\n",
    "    \"Sarasota\": [\"University Park\", \"Myakka City\"],\n",
    "    \"Port Charlotte\": [\"Placida\"],\n",
    "    \"Cape Coral\": [\"Boca Grande\"],\n",
    "    \"Key West\": [\"Little Torch Key\", \"Summerland Key\", \"Naval Air Station Key West\"],\n",
    "    \"Islamorada, Village Of Islands\": [\"Tavernier\", \"Islamorada\"],\n",
    "    \"West Palm Beach\": [\"Singer Island\", \"Golden Lakes\", \"Loxahatchee\"],\n",
    "    \"Boca Raton\": [\"Sandalfoot Cove\"],\n",
    "    \"Naples\": [\"Everglades City\", \"Ochopee\", \"Goodland\"],\n",
    "    \"Fort Myers\": [\"Miromar Lakes\", \"Tice\"],\n",
    "    \"Sebring\": [\"Lorida\", \"Palmdale\"],\n",
    "    \"Kissimmee\": [\"Reunion\", \"Intercession City\"],\n",
    "    \"St. Cloud\": [\"Kenansville\", \"Harmony\", \"St Cloud\"],\n",
    "    \"Lake Wales\": [\"River Ranch\"],\n",
    "    \"Melbourne\": [\"Patrick AFB\", \"Melbourne Beach\", \"Patrick Space Force Base\", \"Patrick Afb\"],\n",
    "    \"Jacksonville\": [\"St. Johns\", \"Ponte Vedra Beach\", \"Mayport\", \"St Johns\"],\n",
    "    \"Fernandina Beach\": [\"Amelia Island\"],\n",
    "    \"Palatka\": [\"Florahome\", \"Georgetown\", \"San Mateo\", \"East Palatka\", \"Satsuma\"],\n",
    "    \"Gainesville\": [\"Keystone Heights\", \"Melrose\", \"Hawthorne\", \"Jonesville\", \"3720 Nw 13Th St Suite #14 Gainesville\"],\n",
    "    \"Ocala\": [\"Fort Mccoy\",\"Citra\", \"Sparr\", \"Fort McCoy\", \"Salt Springs\", \"Belleview\", \"Anthony\"],\n",
    "    \"St. Augustine\": [\"Elkton\", \"Hastings\", \"St Augustine Beach\"],\n",
    "    \"Sanford\": [\"Lake Monroe\"],\n",
    "    \"Deltona\": [\"Osteen\", \"Pierson\", \"DeLand\"],\n",
    "    \"Orlando\": [\"Chuluota\", \"Sand Lake\"],\n",
    "    \"Mount Dora\": [\"Mt Dora\", \"Mt Plymouth\"],\n",
    "    \"The Villages\": [\"Oxford\", \"Summerfield\", \"Weirsdale\", \"Sumterville\"],\n",
    "    \"Beverly Hills\": [\"Pine Ridge\"],\n",
    "    \"Lake City\": [\"Branford\", \"White Springs\", \"Wellborn\", \"Sanderson\"],\n",
    "    \"Chiefland\": [\"Old Town\"],\n",
    "    \"Perry\": [\"Steinhatchee\", \"Horseshoe Beach\"],\n",
    "    \"Apalachicola\": [\"St George Island\"],\n",
    "    \"Tallahassee\": [\"Lamont\", \"St Marks\", \"Wakulla Springs\"],\n",
    "    \"Madison\": [\"Lee\"],\n",
    "    \"Live Oak\": [\"Mayo\", \"Jennings\"],\n",
    "    \"Lake Butler City\": [\"Lake Butler\"],\n",
    "    \"Starke\": [\"Raiford\"],\n",
    "    \"Brooksville\" : [\"Brooksville\",\"Springhill\"],\n",
    "    \"Holmes Beach\" : [\"Holmes Beach\", \"Westville\"]\n",
    "}\n",
    "\n",
    "# Aplicar el diccionario de mapeo para corregir los nombres de las ciudades\n",
    "business['city'] = business['city'].replace(city_mapping_unificado)\n",
    "\n",
    "# Crear un diccionario inverso para el mapeo de ciudades\n",
    "reverse_city_mapping = {alt: official for official, alternatives in city_mapping_unificado.items() for alt in alternatives}\n",
    "\n",
    "# Aplicar el mapeo en la columna 'city' de business\n",
    "business['city'] = business['city'].apply(lambda x: reverse_city_mapping.get(x.strip().title(), x.strip().title()))\n",
    "\n",
    "# Volver a verificar cuántas ciudades coinciden con las oficiales\n",
    "business['city_normalized'] = business['city'].str.strip().str.title()\n",
    "ciudades['city_normalized'] = ciudades['city'].str.strip().str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ciudades sin city_id asignado: 0\n",
      "Empty DataFrame\n",
      "Columns: [city, city_normalized]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Fusionar business con ciudades para obtener city_id\n",
    "business = business.merge(\n",
    "    ciudades[['city_normalized', 'city_id']],  # Solo tomamos city_id de ciudades\n",
    "    left_on='city_normalized', \n",
    "    right_on='city_normalized', \n",
    "    how='left'  # Mantenemos todas las filas de business, aunque no haya coincidencia\n",
    ")\n",
    "\n",
    "\n",
    "# Verificar si quedaron ciudades sin city_id asignado\n",
    "ciudades_sin_id = business[business['city_id'].isna()]\n",
    "\n",
    "# Mostrar cuántas ciudades no obtuvieron un city_id\n",
    "print(f\"Ciudades sin city_id asignado: {len(ciudades_sin_id)}\")\n",
    "\n",
    "# Mostrar algunas ciudades sin city_id para depuración\n",
    "print(ciudades_sin_id[['city', 'city_normalized']].drop_duplicates().head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unir los DataFrames en base a 'business_id'\n",
    "reviews = reviews.merge(business[['business_id', 'id']], on='business_id', how='left')\n",
    "\n",
    "# Eliminar la columna 'business_id'\n",
    "reviews.drop(columns=['business_id'], inplace=True)\n",
    "\n",
    "# Reordenar las columnas para que 'id' sea la primera\n",
    "columnas_ordenadas = ['id'] + [col for col in reviews.columns if col != 'id']\n",
    "reviews = reviews[columnas_ordenadas]\n",
    "reviews = reviews.dropna(subset=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_normal = business.drop(columns=['city', 'state','categories', 'city_normalized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el orden lógico de las columnas\n",
    "column_order = [\n",
    "    # Identificación\n",
    "    'id', \"business_id\", \"name\",\n",
    "\n",
    "    # Ubicación\n",
    "    \"address\", \"postal_code\", \"latitude\", \"longitude\", 'city_id', \n",
    "\n",
    "    # Información general\n",
    "    \"stars\", \"review_count\", \"is_open\", 'category_id',\n",
    "\n",
    "    # Opciones de servicio\n",
    "    \"delivery\", \"takeout\", \"outdoor_seating\", \"drivethrough\",\n",
    "\n",
    "    # Características y comodidades\n",
    "    \"wheelchair_friendly\", \"alcohol_beverage\", \"dancing\",\n",
    "    \"catering\", \"counter_service\", \"seating\", \"dogs_allowed\",\n",
    "    \"bike_parking\", \"parking\",\n",
    "\n",
    "    # Horarios de comida\n",
    "    \"breakfast\", \"lunch\", \"dinner\", \"dessert\",\n",
    "\n",
    "    # Ambiente\n",
    "    \"casual\", \"romantic\", \"formal\", \"trendy\",\n",
    "\n",
    "    # Reservas y tiempos de espera\n",
    "    \"with_reservation\", \n",
    "\n",
    "    # Entretenimiento y características adicionales\n",
    "    \"live_entertainment\",\n",
    "\n",
    "    # Público objetivo\n",
    "    \"groups\", \"kids_friendly\",\n",
    "\n",
    "    # Conectividad y tecnología\n",
    "    \"wifi\", \"bar_onsite\",\n",
    "\n",
    "    # Opciones de pago\n",
    "    \"credit_cards\",\n",
    "]\n",
    "\n",
    "# Aplicar el orden de columnas asegurando que no haya errores por columnas faltantes\n",
    "business_normal = business_normal[column_order]\n",
    "\n",
    "# Guardar el DataFrame final a CSV\n",
    "business_normal.to_csv(r'business_normal.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unificar_registros(df):\n",
    "    \"\"\"\n",
    "    Unifica los registros duplicados en base a la columna 'id'.\n",
    "    \n",
    "    - Mantiene un valor arbitrario para 'gmap_id'.\n",
    "    - Conserva el primer valor de 'name', 'street_address', 'postal_code', 'latitude', 'longitude', 'city_id'.\n",
    "    - Une los valores únicos de 'category_id'.\n",
    "    - Calcula el promedio ponderado de 'stars' usando 'review_count'.\n",
    "    - Suma los valores de 'review_count'.\n",
    "    - Para las columnas binarias, si hay al menos un 1, deja 1; si todos son 0, deja 0.\n",
    "    \n",
    "    Parámetros:\n",
    "    - df: DataFrame con registros duplicados a consolidar.\n",
    "\n",
    "    Retorna:\n",
    "    - DataFrame sin duplicados con valores agregados correctamente.\n",
    "    \"\"\"\n",
    "\n",
    "    # Columnas a mantener el primer valor (todas son iguales)\n",
    "    keep_first = ['business_id', 'name', 'postal_code', 'latitude', 'longitude', 'city_id']\n",
    "\n",
    "    # Reglas de agregación personalizadas\n",
    "    agg_rules = {\n",
    "        'category_id': lambda x: list(set().union(*x)) if x.dtype == 'O' else x,  # Unir listas y dejar valores únicos\n",
    "        'stars': lambda x: (x * df.loc[x.index, 'review_count']).sum() / df.loc[x.index, 'review_count'].sum() if df.loc[x.index, 'review_count'].sum() > 0 else x.mean(),  # Promedio ponderado\n",
    "        'review_count': 'sum'  # Sumar reviews\n",
    "    }\n",
    "\n",
    "    # Identificar las columnas binarias y aplicar \"máximo\" (si hay un 1, queda 1)\n",
    "    binary_columns = [col for col in df.columns if col not in ['id'] + keep_first + list(agg_rules.keys())]\n",
    "    for col in binary_columns:\n",
    "        agg_rules[col] = 'max'\n",
    "\n",
    "    # Aplicar reglas de agregación\n",
    "    df_unificado = df.groupby('id', as_index=False).agg({**{col: 'first' for col in keep_first}, **agg_rules})\n",
    "\n",
    "    return df_unificado\n",
    "\n",
    "# Aplicar la función\n",
    "business_normal = unificar_registros(business_normal)\n",
    "business_normal.drop(columns=['business_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_normal.to_csv(r'data_normalizada\\business_normal.csv', index = False)\n",
    "reviews.to_csv(r'data_normalizada\\reviews_normal.csv', index = False)\n",
    "reviews.to_parquet(r'data_normalizada\\reviews_normal.parquet', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
